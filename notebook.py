# -*- coding: utf-8 -*-
"""xp_io.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hixioXAiUxUrNGwQklo88V7LKfnUHuUo

Import library
"""

import pandas as pd
import json
import re

pd.options.mode.copy_on_write = True

"""Mount and load data function definitions"""

# mount google drive
# def mount_drive():
#   from google.colab import drive
#   drive.mount('/content/drive')
#   return

# load data from json file
# def load_data(path):
#     with open(path, "r") as file:
#         data = json.load(file)
#         return data

debit_keywords = [
    "debited for",
    "debited by",
    "debited",
    "debit by",
    "withdrawn",
    "purchased",
]
credit_keywords = ["credited to", "credited by", "credit for", "credited"]


def categorize_transaction(body):
    body = body.lower()
    transactinType = "unknown"
    keyword = ""
    for i in debit_keywords:
        f = body.find(i)
        if f != -1:
            # print(body, i)
            keyword = i
            transactinType = "debit"
            break
    if transactinType == "unknown":
        for i in credit_keywords:
            f = body.find(i)
            if f != -1:
                # print(body, i)
                keyword = i
                transactinType = "credit"
                break

    return pd.Series([transactinType, keyword])

def lower(body):
    return body.lower()

def extract_refno(message):
    # Updated patterns with named groups for clarity
    patterns = [
        r"\bref[:\s]*(?P<ref_num1>\d+)",
        r"\brefno[:\s]*(?P<ref_num2>\d+)",
        r"\bref\s*no[:\s]*(?P<ref_num3>\d+)",
        r"\bref\s*no\.\s*(?P<ref_num4>\d+)",
        r"\btransaction\s*number[:\s]*(?P<ref_num5>\d+)",
    ]

    # Combine patterns into one with '|' for alternation
    combined_pattern = "|".join(patterns)

    # Check for 'mandate' logic first
    if "mandate" in message.lower():
        last_word = message.strip().split()[-1]
        if last_word.isdigit():
            cleaned_message = " ".join(message.strip().split()[:-1])
            return pd.Series([last_word, cleaned_message])

    # Search for the reference number using the combined pattern
    match = re.search(combined_pattern, message, re.IGNORECASE)

    if match:
        # Extract the first non-None group from the match
        ref_number = next((v for v in match.groupdict().values() if v is not None), "")
        # Clean only the matched reference part from the message
        cleaned_message = re.sub(
            r"\b(ref[:\s]*\d+|refno[:\s]*\d+|ref\s*no\.?\s*\d+|transaction\s*number[:\s]*\d+)",
            "",
            message,
            flags=re.IGNORECASE,
        ).strip()
        return pd.Series([ref_number, cleaned_message])

    # Default return if no match found
    return pd.Series(["", message])

def extract_amount(message):
    # Define the regex patterns for "rs", "inr", and "debited by"

    c = re.sub(r"[^a-zA-Z0-9.\s]", "", message)

    pattern_amount = r"\b(?:rs\.?|inr|â‚¹)\s*(\d+(?:\.\d+)?)"
    pattern_debited = r"\bdebited by\s*(\d+(?:\.\d+)?)"

    # Search for the first match of "rs" or "INR"
    match_amount = re.search(pattern_amount, c, re.IGNORECASE)
    # Search for the first match of "debited by"
    match_debited = re.search(pattern_debited, c, re.IGNORECASE)

    # Prioritize "debited by" if found, otherwise use the amount after "rs" or "INR"
    if match_debited:
        return match_debited.group(1)
    elif match_amount:
        return match_amount.group(1)
    else:
        return 0

def remove_unsuccessful_transaction(
    body,
):
    if (
        (body.find("will be debited") != -1)
        or (body.find("will be credited") != -1)
        or (body.find("can be credited") != -1)
    ):
        return "future"
    elif (
        (body.find("unsucessfull") != -1)
        or (body.find("not completed") != -1)
        or (body.find("data") != -1)
        or (body.find("recharge of") != -1)
        or (body.find("wallet") != -1)
    ):
        return "unsuccessful"
    else:
        return "successful"

def contains_credit_wallet_pattern(message):
    # Define regex pattern to match 'credit to {*} wallet' phrases
    pattern = r"credited to .*? wallet"

    # Check if the pattern is present in the message (case-insensitive)
    return bool(re.search(pattern, message, re.IGNORECASE))

def extract_account_number(body):
    # Regex to find account number (starts with X's followed by digits)
    match = re.search(r"x+\d+", body)

    if match:
        # Extract the account number
        account_number = match.group(0)

        # Remove the 'X's from the account number
        cleaned_account_number = account_number.lstrip(
            "x"
        )  # Removes all 'X's from the beginning

        cleaned_account_number = cleaned_account_number[:4]
        # Replace the full account number (with X's) in the original message with an empty string
        body_cleaned = body.replace(account_number, "")

        return pd.Series(
            [cleaned_account_number, body_cleaned]
        )  # Return both the cleaned account number and the cleaned message
    else:
        return pd.Series(["", body])

def extract_recipient(message):
    # Check for 'debited' to confirm it's a debit transaction
    if "debit" in message.lower() or "debited" in message.lower():
        # Extract between 'credited to' and 'via'
        credited_pattern = r"\bcredited to\s+(.*?)\s+via\b"
        credited_match = re.search(credited_pattern, message, re.IGNORECASE)

        if credited_match:
            return credited_match.group(1)
        if "debited" in message.lower():
            # Extract between "from" and "on"
            from_on_pattern = r"\bfrom\s+(.*?)\s+on\b"
            from_on_match = re.search(from_on_pattern, message, re.IGNORECASE)

            if from_on_match:
                return from_on_match.group(1).strip()

    # Extract after 'trf to' until the period (.)
    trf_pattern = r"\btrf to\s+([^\.]+)"  # Capture everything until the next period
    trf_match = re.search(trf_pattern, message, re.IGNORECASE)

    if trf_match:
        return trf_match.group(1).strip()

    # Extract after 'trf to' until the period (.)
    towards_pattern = (
        r"\btowards\s+(.*?)\s+for\b"  # Capture everything until the next period
    )
    towards_match = re.search(towards_pattern, message, re.IGNORECASE)
    if towards_match:
        return towards_match.group(1).strip()

    c_pattern = r"\bcredited to\s+([^\-]+)"  # Capture everything until the next period
    c_match = re.search(c_pattern, message, re.IGNORECASE)
    if c_match:
        return c_match.group(1).strip()

    t_pattern = r"\btransfer to\s+([^\.]+)"  # Capture everything until the next period
    t_match = re.search(t_pattern, message, re.IGNORECASE)
    if t_match:
        return t_match.group(1).strip()

    g_pattern = (
        r"debited\(trf\)\s*(.*?)\s*in"  # Capture everything until the next period
    )
    g_match = re.search(g_pattern, message, re.IGNORECASE)
    if g_match:
        return g_match.group(1).strip()

    return ""

# mount_drive()

def getExtractedData(data, output):

    # data = load_data(path)

    df = pd.DataFrame(data)

    df = df.drop(["sub_id", "_id", "read", "dateSent", "thread_id"], axis=1)

    df["original_msg"] = df["body"]

    df["body"] = df["body"].apply(lower)

    df[["type", "keyword"]] = df["body"].apply(categorize_transaction)

    df = df.loc[~(df["type"] == "unknown")]

    df["status"] = df["body"].apply(remove_unsuccessful_transaction)

    df = df.loc[(df["status"] == "successful")]

    df["isWallet"] = df["body"].apply(contains_credit_wallet_pattern)
    df = df.loc[~(df["isWallet"])]

    df[["acc_no", "body"]] = df["body"].apply(extract_account_number)

    df[["ref_no", "body"]] = df["body"].apply(extract_refno)

    df["amount"] = df["body"].apply(extract_amount)

    df["credited_to"] = df["body"].apply(extract_recipient)

    df = df.drop(["body", "status", "isWallet"], axis=1)

    data_list = df.to_dict(orient="records")

    return data_list

    # json_data = json.dumps(data_list, indent=4)

    with open(output, "w") as json_file:
        json.dump(data_list, json_file, indent=4)
